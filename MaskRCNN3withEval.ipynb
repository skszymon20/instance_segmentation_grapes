{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZOiV9uakMxc",
        "outputId": "2a0ace8b-dd96-4594-aaee-a36449da4540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wgisd'...\n",
            "remote: Enumerating objects: 4248, done.\u001b[K\n",
            "remote: Counting objects: 100% (848/848), done.\u001b[K\n",
            "remote: Compressing objects: 100% (839/839), done.\u001b[K\n",
            "remote: Total 4248 (delta 19), reused 820 (delta 7), pack-reused 3400\u001b[K\n",
            "Receiving objects: 100% (4248/4248), 1.39 GiB | 30.93 MiB/s, done.\n",
            "Resolving deltas: 100% (342/342), done.\n",
            "Checking out files: 100% (1849/1849), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/thsant/wgisd.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqZQkm5dueL0",
        "outputId": "b21909ae-9087-490a-be43-8722c78fd1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /googledrive; to attempt to forcibly remount, call drive.mount(\"/googledrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "HEIGHT, WIDTH = 1365, 2048\n",
        "MASKTHRESH = 0.5\n",
        "from google.colab import drive\n",
        "drive.mount('/googledrive')\n",
        "MODELPATH = '/googledrive/MyDrive/uczelnia/computer_vision/instance_segmentation_grapes/models/'\n",
        "from random import shuffle\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.ssd import det_utils\n",
        "from torchvision.ops import nms\n",
        "import torchvision\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "import warnings\n",
        "import random\n",
        "import colorsys\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "from matplotlib.patches import Polygon\n",
        "from skimage.color import label2rgb\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def random_colors(n_colors, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / n_colors, 1, brightness) for i in range(n_colors)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n",
        "\n",
        "\n",
        "def plot_item(img, boxes, mask, savename = None, maskthresh = MASKTHRESH):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        img : src image of shape (3, image_height, image_width) e.g. (3, 1365, 2048)\n",
        "        boxes : boxes found objects (n_boxes, 4)\n",
        "        mask : mask of found objects (n_boxes, image_height, image_width)\n",
        "    Examples:\n",
        "        sample parameters shape: ((3, 1365, 2048), (11, 4), (11, 1365, 2048))\n",
        "    \"\"\"\n",
        "    if type(img) == torch.Tensor:\n",
        "        img = img.detach().numpy()\n",
        "    if type(boxes) == torch.Tensor:\n",
        "        boxes = boxes.detach().numpy()\n",
        "    if type(mask) == torch.Tensor:\n",
        "        mask = mask.detach().numpy()\n",
        "    if mask.shape[1] == 1:\n",
        "        mask = mask.squeeze(1)\n",
        "    if mask.dtype != np.uint8:\n",
        "        mask = mask > maskthresh\n",
        "        mask = mask.astype(np.uint8)\n",
        "    fig, (ax0, ax1) = plt.subplots(figsize=(20,10), ncols=2, dpi = 200)\n",
        "\n",
        "    # boxes = boxes[[12], ...]\n",
        "    # mask = mask[[12], ...]\n",
        "\n",
        "    # Number of instances\n",
        "    n_boxes = boxes.shape[0]\n",
        "\n",
        "    # Generate random colors\n",
        "    colors = random_colors(n_boxes)\n",
        "\n",
        "    for i, (x0, y0, x1, y1) in enumerate(boxes):\n",
        "        color = np.array(colors[i])\n",
        "        box_width = x1 - x0\n",
        "        box_height = y1 - y0\n",
        "        p = patches.Rectangle((x0, y0), box_width, box_height, linewidth=2,\n",
        "                              alpha=0.7, linestyle=\"dashed\",\n",
        "                              edgecolor=color, facecolor='none')\n",
        "        ax0.add_patch(p)\n",
        "        ax0.text(x0 + 5, y0 + 25, '%.2d' % i, color=color, weight='bold', size=8)\n",
        "\n",
        "        p = patches.Rectangle((x0, y0), box_width, box_height, linewidth=2,\n",
        "                              alpha=0.7, linestyle=\"dashed\",\n",
        "                              edgecolor=color, facecolor='none')\n",
        "        ax1.add_patch(p)\n",
        "        ax1.text(x0 + 5, y0 + 25, '%.2d' % i, color=color, weight='bold', size=8)\n",
        "        \n",
        "        ax0.imshow(np.moveaxis(img, 0, -1))\n",
        "\n",
        "    mask = np.moveaxis(mask, 0, -1)\n",
        "    labels = np.zeros(mask.shape[0:2])\n",
        "    for i in range(n_boxes):\n",
        "        labels[mask[:,:,i] == 1] = i + 1\n",
        "    mask_rgb = label2rgb(labels, colors=colors, bg_label=0)\n",
        "    ax1.imshow(mask_rgb)\n",
        "    if savename is not None:\n",
        "        plt.savefig(savename)\n",
        "\n",
        "class WGISDMaskedDataset(Dataset):\n",
        "    def __init__(self, root, transforms=None, source='train'):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        if source not in ('train', 'test', 'valid'):\n",
        "            print('source should be by \"train\" or \"test\"')\n",
        "            return None\n",
        "\n",
        "        srcpref = source\n",
        "        if source == 'valid':\n",
        "            srcpref = 'test'\n",
        "        source_path = os.path.join(root, f'{srcpref}_masked.txt')\n",
        "        with open(source_path, 'r') as fp:\n",
        "          lines = fp.readlines()\n",
        "          ids = [l.rstrip() for l in lines]# removes /n at the end of each line\n",
        "\n",
        "        self.imgs = [os.path.join(root, 'data', f'{id}.jpg') for id in ids]\n",
        "        self.masks = [os.path.join(root, 'data', f'{id}.npz') for id in ids]\n",
        "        self.boxes = [os.path.join(root, 'data', f'{id}.txt') for id in ids]\n",
        "\n",
        "        #performing additional dataset split test -> test, valid\n",
        "        if source == 'valid':\n",
        "            self.imgs = self.imgs[len(self.imgs) // 2 : ]\n",
        "            self.masks = self.masks[len(self.masks) // 2 : ]\n",
        "            self.boxes = self.boxes[len(self.boxes) // 2 : ]\n",
        "        elif source == 'test':\n",
        "            self.imgs = self.imgs[ : len(self.imgs) // 2 ]\n",
        "            self.masks = self.masks[ : len(self.masks) // 2 ]\n",
        "            self.boxes = self.boxes[ : len(self.boxes) // 2 ]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.imgs[idx]\n",
        "        mask_path = self.masks[idx]\n",
        "        box_path = self.boxes[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        \n",
        "        if self.transforms is None:\n",
        "            pass\n",
        "        else:\n",
        "            img = np.array(img)\n",
        "            img = self.transforms(torch.as_tensor(img, dtype=torch.uint8))\n",
        "\n",
        "        img = np.array(img)\n",
        "        # Normalize\n",
        "        img = (img - img.min()) / np.max([img.max() - img.min(), 1])\n",
        "        img = np.moveaxis(img, -1, 0)\n",
        "        img = torch.as_tensor(img, dtype=torch.float32)  \n",
        "\n",
        "\n",
        "        wgisd_masks = np.load(mask_path)['arr_0'].astype(np.uint8)\n",
        "        masks = np.moveaxis(wgisd_masks, -1, 0) \n",
        "\n",
        "        num_objs = masks.shape[0]\n",
        "        all_text = np.loadtxt(box_path, delimiter = \" \", dtype = np.float32)\n",
        "        wgisd_boxes = all_text[:,1:]\n",
        "        assert(wgisd_boxes.shape[0] == num_objs)\n",
        "\n",
        "        labels = np.ones(num_objs, dtype=np.int64)\n",
        "\n",
        "        # According to WGISD:\n",
        "        #\n",
        "        # These text files follows the \"YOLO format\"\n",
        "        # \n",
        "        # CLASS CX CY W H\n",
        "        # \n",
        "        # class is an integer defining the object class â€“ the dataset presents \n",
        "        # only the grape class that is numbered 0, so every line starts with \n",
        "        # this \"class zero\" indicator. The center of the bounding box is the \n",
        "        # point (c_x, c_y), represented as float values because this format \n",
        "        # normalizes the coordinates by the image dimensions. To get the \n",
        "        # absolute position, use (2048 c_x, 1365 c_y). The bounding box \n",
        "        # dimensions are given by W and H, also normalized by the image size.\n",
        "        #\n",
        "        # Torchvision's Mask R-CNN expects absolute coordinates.\n",
        "        _, height, width = img.shape\n",
        "\n",
        "        boxes = []\n",
        "        for box in wgisd_boxes:\n",
        "            x1 = box[0] - box[2]/2\n",
        "            x2 = box[0] + box[2]/2\n",
        "            y1 = box[1] - box[3]/2\n",
        "            y2 = box[1] + box[3]/2\n",
        "            boxes.append([x1 * width, y1 * height, x2 * width, y2 * height])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": image_id\n",
        "        }\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "def get_maskrcnn(pretrained = True):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=pretrained)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    #replace head predictor (boxes)\n",
        "    NUM_CLASSES=2\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    #replace mask predictor\n",
        "    fg_iou_thresh = 0.6 #min IoU to be considered as positive\n",
        "    bg_iou_thresh = 0.6 #max IoU to be considered as negative\n",
        "    model.roi_heads.proposal_matcher.low_threshold = bg_iou_thresh\n",
        "    model.roi_heads.proposal_matcher.high_threshold = fg_iou_thresh\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, NUM_CLASSES)\n",
        "    return model\n",
        "\n",
        "def filter_results(results : dict, confidence_thresh = 0.8):\n",
        "    \"\"\"\n",
        "    filters results in situ\n",
        "    \"\"\"\n",
        "    scores = results['scores']\n",
        "    results['boxes'] = results['boxes'][scores > confidence_thresh]\n",
        "    results['labels'] = results['labels'][scores >confidence_thresh]\n",
        "    results['masks'] = results['masks'][scores>confidence_thresh]\n",
        "    results['scores'] = results['scores'][scores > confidence_thresh]\n",
        "    return results\n",
        "\n",
        "def nmscombined(orig_predicted, iou_thresh = 0.3):\n",
        "    '''\n",
        "    performs non max suppression on the results\n",
        "    '''\n",
        "    keep = nms(orig_predicted['boxes'], orig_predicted['scores'], iou_thresh)\n",
        "    final_pred = orig_predicted\n",
        "    final_pred['boxes'] = final_pred['boxes'][keep]\n",
        "    final_pred['masks'] = final_pred['masks'][keep]\n",
        "    final_pred['scores'] = final_pred['scores'][keep]\n",
        "    final_pred['labels'] = final_pred['labels'][keep]\n",
        "    return final_pred\n",
        "\n",
        "def average_precision(GTmasks, predmasks, maskthresh = MASKTHRESH):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    GTmasks : Ground Truth masks\n",
        "    predmasks : Predicted Masks from the model\n",
        "    \n",
        "    Returns\n",
        "    ------------\n",
        "    Precision\n",
        "    \"\"\"\n",
        "    predmasks = predmasks > maskthresh\n",
        "    #for each predmask compute nearest neighbor and return precision\n",
        "    loss = 0\n",
        "    npreds =0\n",
        "    for predmask in predmasks:\n",
        "        andresult=torch.logical_and(GTmasks, predmask )\n",
        "        imgid = torch.argmax(andresult.sum([-1, -2]))\n",
        "        gtmask = GTmasks[imgid]\n",
        "        N_TP = torch.logical_and(gtmask, predmask).sum()\n",
        "        N_FP = predmask.sum() - N_TP\n",
        "        loss += N_TP / (N_TP + N_FP)\n",
        "        npreds +=1\n",
        "    return loss / npreds\n",
        "\n",
        "def average_recall(GTmasks, predmasks, maskthresh = MASKTHRESH):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    GTmasks : Ground Truth masks\n",
        "    predmasks : Predicted Masks from the model\n",
        "    \n",
        "    Returns\n",
        "    ------------\n",
        "    Recall\n",
        "    \"\"\"\n",
        "    predmasks = predmasks > maskthresh\n",
        "    #for each predmask compute nearest neighbor and return recall\n",
        "    loss = 0\n",
        "    npreds =0\n",
        "    for predmask in predmasks:\n",
        "        andresult=torch.logical_and(GTmasks, predmask )\n",
        "        imgid = torch.argmax(andresult.sum([-1, -2]))\n",
        "        gtmask = GTmasks[imgid]\n",
        "        N_TP = torch.logical_and(gtmask, predmask).sum()\n",
        "        N_FN = gtmask.sum() - N_TP\n",
        "        loss += N_TP / (N_TP + N_FN)\n",
        "        npreds +=1\n",
        "    return loss / npreds\n",
        "\n",
        "def fscore_(precision, recall):\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "def fscore(GTmasks, predmasks, maskthresh = MASKTHRESH):\n",
        "    predmasks = predmasks > maskthresh\n",
        "    #for each predmask compute nearest neighbor and return precision\n",
        "    precloss = 0\n",
        "    recloss = 0\n",
        "    npreds =0\n",
        "    for predmask in predmasks:\n",
        "        andresult=torch.logical_and(GTmasks, predmask )\n",
        "        imgid = torch.argmax(andresult.sum([-1, -2]))\n",
        "        gtmask = GTmasks[imgid]\n",
        "        N_TP = torch.logical_and(gtmask, predmask).sum()\n",
        "        N_FP = predmask.sum() - N_TP\n",
        "        N_FN = gtmask.sum() - N_TP\n",
        "        precloss += N_TP / (N_TP + N_FP)\n",
        "        recloss += N_TP / (N_TP + N_FN)\n",
        "        npreds +=1\n",
        "    precision = precloss / npreds\n",
        "    recall = recloss / npreds\n",
        "\n",
        "    return fscore_(precision, recall)\n",
        "\n",
        "def print_datsetslens():\n",
        "    train=WGISDMaskedDataset('./wgisd/', source='train')\n",
        "    test=WGISDMaskedDataset('./wgisd/', source='test')\n",
        "    valid = WGISDMaskedDataset('./wgisd/', source='valid')\n",
        "    print('trainlen:', len(train))\n",
        "    print('testlen:', len(test))\n",
        "    print('validlen:', len(valid))\n",
        "    den = len(train) + len(valid) + len(test)\n",
        "    print(f'split proportion: {len(train) / den} : {len(test) / den} : {len(valid) / den}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPYtK8x00lLW",
        "outputId": "9d3708a0-1df2-404f-c9ce-e1dd258824e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finalepoch1: lossmask:0.2906045615673065; loss:0.9145166277885437; lossmaskacc:22.47536252439022; lossacc: 71.47234070301056;\n",
            "finalepoch2: lossmask:0.22981758415699005; loss:0.945505678653717; lossmaskacc:14.322275921702385; lossacc: 48.234725534915924;\n",
            "finalepoch3: lossmask:0.27388039231300354; loss:0.7837556004524231; lossmaskacc:13.270611241459846; lossacc: 42.8925878405571;\n",
            "finalepoch4: lossmask:0.23466838896274567; loss:0.6725770235061646; lossmaskacc:12.639134913682938; lossacc: 38.76751062273979;\n",
            "finalepoch5: lossmask:0.23341745138168335; loss:0.7471639513969421; lossmaskacc:12.080042526125908; lossacc: 34.735831797122955;\n",
            "finalepoch6: lossmask:0.2321588546037674; loss:0.9405063986778259; lossmaskacc:11.809507131576538; lossacc: 32.27685680985451;\n",
            "finalepoch7: lossmask:0.17528963088989258; loss:0.4604153335094452; lossmaskacc:11.474566832184792; lossacc: 30.044736325740814;\n",
            "finalepoch8: lossmask:0.2607760727405548; loss:0.7247419357299805; lossmaskacc:11.163489237427711; lossacc: 27.90701723098755;\n",
            "finalepoch9: lossmask:0.14848299324512482; loss:0.3396579325199127; lossmaskacc:10.964436039328575; lossacc: 26.288524985313416;\n",
            "finalepoch10: lossmask:0.19829218089580536; loss:0.45983102917671204; lossmaskacc:10.742233216762543; lossacc: 24.921596705913544;\n"
          ]
        }
      ],
      "source": [
        "MODELNAME='model3.pt'\n",
        "LOGPREFIX = 'logof_'\n",
        "savemodel = True\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(0)\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "MOMENTUM = 0.9\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "logging.basicConfig(\n",
        "    format='%(levelname)s: %(asctime)s %(message)s',\n",
        "    level = logging.DEBUG,\n",
        "    filename = os.path.join(MODELPATH,LOGPREFIX + MODELNAME.split('.')[0] + '.txt'),\n",
        "    filemode='a'\n",
        ")\n",
        "\n",
        "dataset = WGISDMaskedDataset('./wgisd')\n",
        "dataloader = DataLoader(dataset, BATCH_SIZE, shuffle=True, num_workers = 2, collate_fn=lambda s: tuple(zip(*s)))\n",
        "\n",
        "model = get_maskrcnn()\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "logging.info(f'DEVICE: {DEVICE}')\n",
        "model.to(DEVICE)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "model.train()\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "n_batches = len(dataloader)\n",
        "totallosses_inepochs = []\n",
        "masklosses_inepochs =[]\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    logging.info(f'Current epoch: {epoch} of {NUM_EPOCHS}')\n",
        "    lossacc= 0.0\n",
        "    lossmaskacc = 0.0\n",
        "    for batchid, (images, targets) in enumerate(dataloader, 1):\n",
        "        images = [image.to(DEVICE) for image in images]\n",
        "        targets = [ {k : v.to(DEVICE) for k, v in t.items()}for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        #backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # #logs\n",
        "        lossmask=loss_dict['loss_mask'].item()\n",
        "        lossmaskacc += lossmask\n",
        "        lossacc += loss.item()\n",
        "        if (batchid % 25 ==0):\n",
        "            logging.info(f'lossmask:{lossmask}; loss:{loss.item()}; lossmaskacc:{lossmaskacc}; lossacc: {lossacc};')\n",
        "    #TODO add validation loss calculation\n",
        "    logging.info(f'finalepoch{epoch}: lossmask:{lossmask}; loss:{loss.item()}; lossmaskacc:{lossmaskacc}; lossacc: {lossacc};')\n",
        "    print(f'finalepoch{epoch}: lossmask:{lossmask}; loss:{loss.item()}; lossmaskacc:{lossmaskacc}; lossacc: {lossacc};')\n",
        "    totallosses_inepochs.append(lossacc)\n",
        "    masklosses_inepochs.append(lossmaskacc)\n",
        "if savemodel == True:\n",
        "    torch.save(model.state_dict(), os.path.join(MODELPATH, MODELNAME))\n",
        "logging.info(f'totallosses_inepochs: {totallosses_inepochs}')\n",
        "logging.info(f'masklosses_inepochs: {masklosses_inepochs}')\n",
        "logging.info('finished')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM8RIsqvh_3T"
      },
      "source": [
        "Below we perform visualization of results:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0arKC6eiAFL",
        "outputId": "991c73e7-2021-406f-e479-faf7e54cbd77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: 13 pred: 19\n"
          ]
        }
      ],
      "source": [
        "LOADMODELNAME='model3.pt'\n",
        "model = get_maskrcnn()\n",
        "if torch.cuda.is_available():\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME)))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME), map_location=torch.device('cpu')))\n",
        "\n",
        "dataset=WGISDMaskedDataset('./wgisd/', source='train')\n",
        "model.eval()\n",
        "\n",
        "im, targets = dataset[0]\n",
        "# cv2_imshow(np.moveaxis((im * 255).detach().numpy(), 0, -1))\n",
        "res = model([im])\n",
        "res = res[0] # only one image\n",
        "boxes = res['boxes']\n",
        "masks = res['masks']\n",
        "srcboxes = targets['boxes']\n",
        "srcmasks = targets['masks']\n",
        "print(\"src:\", srcboxes.shape[0], 'pred:', boxes.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_item(im, boxes, masks, './train1pred')\n",
        "plot_item(im, srcboxes, srcmasks, './train1src')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9lRvaqTHkCZN",
        "outputId": "43562f07-9111-46e0-a926-a9609ad7ec0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_results(res)\n",
        "boxes = res['boxes']\n",
        "masks = res['masks']\n",
        "print(\"src:\", srcboxes.shape[0], 'pred:', boxes.shape[0])\n",
        "plot_item(im, boxes, masks, './train1predfilter')\n",
        "plot_item(im, srcboxes, srcmasks, './train1srcfilter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5R-VETAwfTIb",
        "outputId": "572a087c-9f21-429c-8263-12ad7f76da28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions on test dataset"
      ],
      "metadata": {
        "id": "sn6qOnRiboGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dimP97k8iAVL",
        "outputId": "200592f6-c93a-4da1-da6b-0c6a49457daf"
      },
      "outputs": [],
      "source": [
        "LOADMODELNAME='model3.pt'\n",
        "model = get_maskrcnn()\n",
        "if torch.cuda.is_available():\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME)))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME), map_location=torch.device('cpu')))\n",
        "\n",
        "dataset=WGISDMaskedDataset('./wgisd/', source='test')\n",
        "model.eval()\n",
        "\n",
        "im, targets = dataset[0]\n",
        "res = model([im])\n",
        "res = res[0] # only one image\n",
        "filter_results(res)\n",
        "boxes = res['boxes']\n",
        "masks = res['masks']\n",
        "srcboxes = targets['boxes']\n",
        "srcmasks = targets['masks']\n",
        "print(\"src:\", srcboxes.shape[0], 'pred:', boxes.shape[0])\n",
        "plot_item(im, boxes, masks, './test1predfilter')\n",
        "plot_item(im, srcboxes, srcmasks, './test1srcfilter')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and view the metrics"
      ],
      "metadata": {
        "id": "m22rwgosxpXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('totallosses_inepochs:')\n",
        "plt.plot(totallosses_inepochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_F1BM0ehno5t",
        "outputId": "d44a1a76-96a3-4179-9e05-424a0c607ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "totallosses_inepochs:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f473822e950>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('masklosses_inepochs:')\n",
        "plt.plot(masklosses_inepochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "c-SqFPgRn7vV",
        "outputId": "2ce05f54-9c6a-4fb8-a14a-b4095238132c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masklosses_inepochs:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f473859b890>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res['scores']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcUerbW0_EEM",
        "outputId": "555a660a-ab8a-4154-e65b-c6a8fe6225ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9993, 0.9993, 0.9992, 0.9986, 0.9983, 0.9983, 0.9976, 0.9969, 0.9960,\n",
              "        0.9959, 0.9948, 0.9938, 0.9833, 0.9708, 0.9645, 0.9557, 0.9089, 0.8975,\n",
              "        0.6357, 0.5859], grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOADMODELNAME='model3.pt'\n",
        "model = get_maskrcnn()\n",
        "if torch.cuda.is_available():\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME)))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(os.path.join(MODELPATH, LOADMODELNAME), map_location=torch.device('cpu')))\n",
        "\n",
        "dataset=WGISDMaskedDataset('./wgisd/', source='test')\n",
        "model.eval()\n",
        "\n",
        "im, targets = dataset[0]\n",
        "res = model([im])\n",
        "res = res[0] # only one image\n",
        "filter_results(res)\n",
        "pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f72ad025319b4d969268670f7eade91e",
            "749d96239be8446bb826836ec99d72c8",
            "4056a414d24d48b28ad8eef9774cb859",
            "b5a1e2d0b7864792acb49ea852d1e70d",
            "a2bae5af5b0c46609ad46e422089b689",
            "475937ffad4b4c5b82500c6ac8fb5582",
            "ea222d08abfa40019ff9560f763e2032",
            "a9d418cb7af04bda936d94e49421cb99",
            "71156928afc6484d8af30b5e5d2d0e36",
            "ab50a4b9e8484932995a5f4584823743",
            "84b7158cebfd4c3ebc2f0684a2b3f05d"
          ]
        },
        "id": "FYjB4GBzzAqt",
        "outputId": "b5dd2fdf-0a3f-4d5b-cdfd-9fc12958e709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f72ad025319b4d969268670f7eade91e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avgprec= average_precision(targets['masks'], res['masks'])\n",
        "avgrec = average_recall(targets['masks'], res['masks'])\n",
        "fres = fscore(targets['masks'], res['masks'])\n",
        "print(\"Precision:\",avgprec)\n",
        "print(\"Recall:\", avgrec)\n",
        "print(\"F1-score:\", fres)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Yqr8gFYbfF",
        "outputId": "939a9532-b588-4ae4-acd2-238173c069d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: tensor(0.8965)\n",
            "Recall: tensor(0.8179)\n",
            "F1-score: tensor(0.8554)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time fscore(targets['masks'], res['masks'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1hV2njt-_fS",
        "outputId": "c266c089-1fbc-47ad-d7d0-8c116cc0c9a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.74 s, sys: 82.2 ms, total: 4.82 s\n",
            "Wall time: 5.01 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8554)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform evaluation on test dataset and validation dataset:"
      ],
      "metadata": {
        "id": "VO3jVJ463-96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_datsetslens()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_uF0ZGg4ILV",
        "outputId": "1ba71894-0785-4f84-c993-f194661916a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainlen: 110\n",
            "testlen: 14\n",
            "validlen: 14\n",
            "split proportion: 0.7971014492753623 : 0.10144927536231885 : 0.10144927536231885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics that we choice are precisision and recall, which are evaluated in terms of number of pixels"
      ],
      "metadata": {
        "id": "Yfbv0IbYonZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2NHfoC6xpdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8a51be-b929-49ac-b8a8-a2ecb895ecf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /googledrive/MyDrive/uczelnia/computer_vision/instance_segmentation_grapes/models/logof_model3.txt: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cat /googledrive/MyDrive/uczelnia/computer_vision/instance_segmentation_grapes/models/logof_model3.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EvaluateMaskRCNN3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f72ad025319b4d969268670f7eade91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_749d96239be8446bb826836ec99d72c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4056a414d24d48b28ad8eef9774cb859",
              "IPY_MODEL_b5a1e2d0b7864792acb49ea852d1e70d",
              "IPY_MODEL_a2bae5af5b0c46609ad46e422089b689"
            ]
          }
        },
        "749d96239be8446bb826836ec99d72c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4056a414d24d48b28ad8eef9774cb859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_475937ffad4b4c5b82500c6ac8fb5582",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea222d08abfa40019ff9560f763e2032"
          }
        },
        "b5a1e2d0b7864792acb49ea852d1e70d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a9d418cb7af04bda936d94e49421cb99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178090079,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178090079,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71156928afc6484d8af30b5e5d2d0e36"
          }
        },
        "a2bae5af5b0c46609ad46e422089b689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab50a4b9e8484932995a5f4584823743",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170M/170M [00:02&lt;00:00, 68.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84b7158cebfd4c3ebc2f0684a2b3f05d"
          }
        },
        "475937ffad4b4c5b82500c6ac8fb5582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea222d08abfa40019ff9560f763e2032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9d418cb7af04bda936d94e49421cb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71156928afc6484d8af30b5e5d2d0e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab50a4b9e8484932995a5f4584823743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84b7158cebfd4c3ebc2f0684a2b3f05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}