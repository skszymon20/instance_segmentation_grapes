{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqZQkm5dueL0","outputId":"c82467eb-7525-4ef1-8056-dd5601b0727f","executionInfo":{"status":"ok","timestamp":1643237426489,"user_tz":-60,"elapsed":72001,"user":{"displayName":"kposk skpo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05760435175705162862"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'wgisd'...\n","remote: Enumerating objects: 4248, done.\u001b[K\n","remote: Counting objects: 100% (848/848), done.\u001b[K\n","remote: Compressing objects: 100% (839/839), done.\u001b[K\n","remote: Total 4248 (delta 19), reused 820 (delta 7), pack-reused 3400\u001b[K\n","Receiving objects: 100% (4248/4248), 1.39 GiB | 34.02 MiB/s, done.\n","Resolving deltas: 100% (342/342), done.\n","Checking out files: 100% (1849/1849), done.\n","Mounted at /googledrive\n"]}],"source":["#@title\n","! git clone https://github.com/thsant/wgisd.git\n","HEIGHT, WIDTH = 1365, 2048\n","MASKTHRESH = 0.5\n","from google.colab import drive\n","drive.mount('/googledrive')\n","from random import shuffle\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.ssd import det_utils\n","from torchvision.ops import nms\n","import torchvision\n","import logging\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import torch\n","import warnings\n","import random\n","import colorsys\n","import matplotlib.pyplot as plt\n","from matplotlib import patches\n","from matplotlib.patches import Polygon\n","from skimage.color import label2rgb\n","import torch.nn.functional as F\n","from torchvision.ops import roi_align\n","from torchvision.models.detection.roi_heads import project_masks_on_boxes\n","from time import time\n","from pathlib import Path\n","import json\n","\n","def random_colors(n_colors, bright=True):\n","    \"\"\"\n","    Generate random colors.\n","    To get visually distinct colors, generate them in HSV space then\n","    convert to RGB.\n","    \"\"\"\n","    brightness = 1.0 if bright else 0.7\n","    hsv = [(i / n_colors, 1, brightness) for i in range(n_colors)]\n","    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n","    random.shuffle(colors)\n","    return colors\n","\n","\n","def plot_item(img, boxes, mask, savename = None, maskthresh = MASKTHRESH):\n","    \"\"\"\n","    Parameters:\n","        img : src image of shape (3, image_height, image_width) e.g. (3, 1365, 2048)\n","        boxes : boxes found objects (n_boxes, 4)\n","        mask : mask of found objects (n_boxes, image_height, image_width)\n","    Examples:\n","        sample parameters shape: ((3, 1365, 2048), (11, 4), (11, 1365, 2048))\n","    \"\"\"\n","    if type(img) == torch.Tensor:\n","        img = img.detach().numpy()\n","    if type(boxes) == torch.Tensor:\n","        boxes = boxes.detach().numpy()\n","    if type(mask) == torch.Tensor:\n","        mask = mask.detach().numpy()\n","    if mask.shape[1] == 1:\n","        mask = mask.squeeze(1)\n","    if mask.dtype != np.uint8:\n","        mask = mask > maskthresh\n","        mask = mask.astype(np.uint8)\n","    fig, (ax0, ax1) = plt.subplots(figsize=(20,10), ncols=2, dpi = 200)\n","\n","    # Number of instances\n","    n_boxes = boxes.shape[0]\n","\n","    # Generate random colors\n","    colors = random_colors(n_boxes)\n","\n","    for i, (x0, y0, x1, y1) in enumerate(boxes):\n","        color = np.array(colors[i])\n","        box_width = x1 - x0\n","        box_height = y1 - y0\n","        p = patches.Rectangle((x0, y0), box_width, box_height, linewidth=2,\n","                              alpha=0.7, linestyle=\"dashed\",\n","                              edgecolor=color, facecolor='none')\n","        ax0.add_patch(p)\n","        ax0.text(x0 + 5, y0 + 25, '%.2d' % i, color=color, weight='bold', size=8)\n","\n","        p = patches.Rectangle((x0, y0), box_width, box_height, linewidth=2,\n","                              alpha=0.7, linestyle=\"dashed\",\n","                              edgecolor=color, facecolor='none')\n","        ax1.add_patch(p)\n","        ax1.text(x0 + 5, y0 + 25, '%.2d' % i, color=color, weight='bold', size=8)\n","        \n","        ax0.imshow(np.moveaxis(img, 0, -1))\n","\n","    mask = np.moveaxis(mask, 0, -1)\n","    labels = np.zeros(mask.shape[0:2])\n","    for i in range(n_boxes):\n","        labels[mask[:,:,i] == 1] = i + 1\n","    mask_rgb = label2rgb(labels, colors=colors, bg_label=0)\n","    ax1.imshow(mask_rgb)\n","    if savename is not None:\n","        plt.savefig(savename)\n","\n","class WGISDMaskedDataset(Dataset):\n","    def __init__(self, root, transforms=None, source='train'):\n","        self.root = root\n","        self.transforms = transforms\n","        \n","        if source not in ('train', 'test', 'valid'):\n","            print('source should be by \"train\" or \"test\"')\n","            return None\n","\n","        srcpref = source\n","        if source == 'valid':\n","            srcpref = 'test'\n","        source_path = os.path.join(root, f'{srcpref}_masked.txt')\n","        with open(source_path, 'r') as fp:\n","          lines = fp.readlines()\n","          ids = [l.rstrip() for l in lines]# removes /n at the end of each line\n","\n","        self.imgs = [os.path.join(root, 'data', f'{id}.jpg') for id in ids]\n","        self.masks = [os.path.join(root, 'data', f'{id}.npz') for id in ids]\n","        self.boxes = [os.path.join(root, 'data', f'{id}.txt') for id in ids]\n","\n","        #performing additional dataset split test -> test, valid\n","        if source == 'test':\n","            self.imgs = self.imgs[len(self.imgs) // 2 : ]\n","            self.masks = self.masks[len(self.masks) // 2 : ]\n","            self.boxes = self.boxes[len(self.boxes) // 2 : ]\n","        elif source == 'valid':\n","            self.imgs = self.imgs[ : len(self.imgs) // 2 ]\n","            self.masks = self.masks[ : len(self.masks) // 2 ]\n","            self.boxes = self.boxes[ : len(self.boxes) // 2 ]\n","\n","    def __getitem__(self, idx):\n","        img_path = self.imgs[idx]\n","        mask_path = self.masks[idx]\n","        box_path = self.boxes[idx]\n","\n","        img = Image.open(img_path).convert(\"RGB\")\n","        \n","        if self.transforms is None:\n","            pass\n","        else:\n","            img = np.array(img)\n","            img = self.transforms(torch.as_tensor(img, dtype=torch.uint8))\n","\n","        img = np.array(img)\n","        # Normalize\n","        img = (img - img.min()) / np.max([img.max() - img.min(), 1])\n","        img = np.moveaxis(img, -1, 0)\n","        img = torch.as_tensor(img, dtype=torch.float32)  \n","\n","\n","        wgisd_masks = np.load(mask_path)['arr_0'].astype(np.uint8)\n","        masks = np.moveaxis(wgisd_masks, -1, 0) \n","\n","        num_objs = masks.shape[0]\n","        all_text = np.loadtxt(box_path, delimiter = \" \", dtype = np.float32)\n","        wgisd_boxes = all_text[:,1:]\n","        assert(wgisd_boxes.shape[0] == num_objs)\n","\n","        labels = np.ones(num_objs, dtype=np.int64)\n","\n","        # According to WGISD:\n","        #\n","        # These text files follows the \"YOLO format\"\n","        # \n","        # CLASS CX CY W H\n","        # \n","        # class is an integer defining the object class â€“ the dataset presents \n","        # only the grape class that is numbered 0, so every line starts with \n","        # this \"class zero\" indicator. The center of the bounding box is the \n","        # point (c_x, c_y), represented as float values because this format \n","        # normalizes the coordinates by the image dimensions. To get the \n","        # absolute position, use (2048 c_x, 1365 c_y). The bounding box \n","        # dimensions are given by W and H, also normalized by the image size.\n","        #\n","        # Torchvision's Mask R-CNN expects absolute coordinates.\n","        _, height, width = img.shape\n","\n","        boxes = []\n","        for box in wgisd_boxes:\n","            x1 = box[0] - box[2]/2\n","            x2 = box[0] + box[2]/2\n","            y1 = box[1] - box[3]/2\n","            y2 = box[1] + box[3]/2\n","            boxes.append([x1 * width, y1 * height, x2 * width, y2 * height])\n","\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        labels = torch.ones((num_objs,), dtype=torch.int64)\n","        masks = torch.as_tensor(masks, dtype=torch.uint8)\n","        image_id = torch.tensor([idx])\n","\n","        target = {\n","            \"boxes\": boxes,\n","            \"labels\": labels,\n","            \"masks\": masks,\n","            \"image_id\": image_id\n","        }\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","def filter_results(results : dict, confidence_thresh = 0.8):\n","    res = results.copy()\n","    scores = results['scores']\n","    res['boxes'] = results['boxes'][scores > confidence_thresh]\n","    res['labels'] = results['labels'][scores >confidence_thresh]\n","    res['masks'] = results['masks'][scores>confidence_thresh]\n","    res['scores'] = results['scores'][scores > confidence_thresh]\n","    return res\n","\n","def nmscombined(orig_predicted, iou_thresh = 0.3):\n","    '''\n","    performs non max suppression on the results\n","    '''\n","    keep = nms(orig_predicted['boxes'], orig_predicted['scores'], iou_thresh)\n","    final_pred = orig_predicted\n","    final_pred['boxes'] = final_pred['boxes'][keep]\n","    final_pred['masks'] = final_pred['masks'][keep]\n","    final_pred['scores'] = final_pred['scores'][keep]\n","    final_pred['labels'] = final_pred['labels'][keep]\n","    return final_pred\n","\n","def calcTP(GTmasks, predmasks, predscores, IoU_thresh = 0.5, maskthresh = MASKTHRESH):\n","    \"\"\"\n","    Parameters\n","    ----------\n","    GTmasks : Ground Truth masks\n","    predmasks : Predicted Masks from the model\n","    \n","    Returns\n","    ------------\n","    TruePositives\n","    \"\"\"\n","    predmasks = predmasks > maskthresh\n","    metric = 0\n","    GTmasksEvaluated = [False for i in range(GTmasks.shape[0])]\n","    TP = 0\n","    for predmask in predmasks[predscores.argsort(descending = True)]:\n","        andresult=torch.logical_and(GTmasks, predmask )\n","        imgid = torch.argmax(andresult.sum([-1, -2]))\n","        if GTmasksEvaluated[imgid]:\n","            continue\n","        gtmask = GTmasks[imgid]\n","        intersection = andresult[imgid]\n","        union = torch.logical_or(gtmask, predmask)\n","        iou = intersection.sum() / union.sum()\n","        if iou >= IoU_thresh:\n","            GTmasksEvaluated[imgid] = True\n","            TP += 1\n","    return TP\n","\n","def precision_frompreds(GTmasks, predmasks, predscores, IoU_thresh = 0.5, maskthresh = MASKTHRESH):\n","    TP = calcTP(GTmasks, predmasks, predscores, IoU_thresh, maskthresh)\n","    return TP / predmasks.shape[0]\n","\n","def recall_frompreds(GTmasks, predmasks, predscores, IoU_thresh = 0.5,maskthresh = MASKTHRESH):\n","    TP = calcTP(GTmasks, predmasks, predscores, IoU_thresh, maskthresh)\n","    return TP / GTmasks.shape[0]\n","\n","def fscore(precision, recall):\n","    return 2 * precision * recall / (precision + recall)\n","\n","def print_datsetslens():\n","    train=WGISDMaskedDataset('./wgisd/', source='train')\n","    test=WGISDMaskedDataset('./wgisd/', source='test')\n","    valid = WGISDMaskedDataset('./wgisd/', source='valid')\n","    print('trainlen:', len(train))\n","    print('testlen:', len(test))\n","    print('validlen:', len(valid))\n","    den = len(train) + len(valid) + len(test)\n","    print(f'split proportion: {len(train) / den} : {len(test) / den} : {len(valid) / den}')\n","\n","class DiceLoss(torch.nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceLoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        intersection = (inputs * targets).sum()                            \n","        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n","        \n","        return 1 - dice\n","\n","class IoULoss(torch.nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(IoULoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","        \n","        #comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = torch.sigmoid(inputs)       \n","        \n","        #flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","        \n","        #intersection is equivalent to True Positive count\n","        #union is the mutually inclusive area of all labels & predictions \n","        intersection = (inputs * targets).sum()\n","        total = (inputs + targets).sum()\n","        union = total - intersection \n","        \n","        IoU = (intersection + smooth)/(union + smooth)\n","                \n","        return 1 - IoU\n","\n","\n","class LossIntoMaskRCNN(object):\n","    def __init__(self, lossfunction = 'bincrossentr_wl'):\n","        if lossfunction == 'bincrossentr_wl':\n","            self.loss = F.binary_cross_entropy_with_logits\n","        elif lossfunction == 'mse':\n","            self.loss = F.mse_loss\n","        elif lossfunction =='dice':\n","            self.loss = DiceLoss()\n","        elif lossfunction == 'iou':\n","            self.loss = IoULoss()\n","    def lossintomaskrcnn(self, mask_logits, proposals, gt_masks, gt_labels, mask_matched_idxs, loss = 'bincrossentr_wl'): \n","        # type: (Tensor, List[Tensor], List[Tensor], List[Tensor], List[Tensor]) \n","        \"\"\" \n","        Arguments: \n","            proposals (list[BoxList]) \n","            mask_logits (Tensor) \n","            targets (list[BoxList]) \n","\n","        Return: \n","            mask_loss (Tensor): scalar tensor containing the loss \n","        \"\"\" \n","\n","        discretization_size = mask_logits.shape[-1] \n","        labels = [l[idxs] for l, idxs in zip(gt_labels, mask_matched_idxs)] \n","        mask_targets = [ \n","            project_masks_on_boxes(m, p, i, discretization_size) \n","            for m, p, i in zip(gt_masks, proposals, mask_matched_idxs) \n","        ] \n","\n","        labels = torch.cat(labels, dim=0) \n","        mask_targets = torch.cat(mask_targets, dim=0) \n","\n","        # torch.mean (in binary_cross_entropy_with_logits) doesn't \n","        # accept empty tensors, so handle it separately \n","        if mask_targets.numel() == 0: \n","            return mask_logits.sum() * 0 \n","\n","        mask_loss = self.loss( \n","            mask_logits[torch.arange(labels.shape[0], device=labels.device), labels], mask_targets \n","        ) \n","        return mask_loss\n","\n","def availablelosses():\n","    return ['bincrossentr_wl', 'dice', 'iou', 'mse']\n","def availablelosses_tofunctions():\n","    return {'bincrossentr_wl':F.binary_cross_entropy_with_logits, 'dice':DiceLoss(), 'iou':IoULoss(),'mse':F.mse_loss}\n","\n","def setloss(loss = 'bincrossentr_wl'):\n","    lossIMRCNN = LossIntoMaskRCNN(loss)\n","    torchvision.models.detection.roi_heads.maskrcnn_loss = lossIMRCNN.lossintomaskrcnn \n","\n","def eager_outputs_foo(losses, detections):\n","    return losses, detections\n","\n","def get_maskrcnn(pretrained = True):\n","    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=pretrained)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    #replace head predictor (boxes)\n","    NUM_CLASSES=2\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n","    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","    hidden_layer = 256\n","    #replace mask predictor\n","    fg_iou_thresh = 0.5 #min IoU to be considered as positive\n","    bg_iou_thresh = 0.5 #max IoU to be considered as negative\n","    model.roi_heads.proposal_matcher.low_threshold = bg_iou_thresh\n","    model.roi_heads.proposal_matcher.high_threshold = fg_iou_thresh\n","    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, NUM_CLASSES)\n","    # model.eager_outputs = eager_outputs_foo\n","    return model"]},{"cell_type":"code","source":["MODELPATH = '/googledrive/MyDrive/'"],"metadata":{"id":"lh3-MlyukdlH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Datasets lens:"],"metadata":{"id":"_KMsQ_1JpM_o"}},{"cell_type":"code","source":["print_datsetslens()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"es_yUpBhpPEH","outputId":"336b10f1-cb90-4a42-8e38-41a27d3aeebd","executionInfo":{"status":"ok","timestamp":1643237426491,"user_tz":-60,"elapsed":11,"user":{"displayName":"kposk skpo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05760435175705162862"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainlen: 110\n","testlen: 14\n","validlen: 14\n","split proportion: 0.7971014492753623 : 0.10144927536231885 : 0.10144927536231885\n"]}]},{"cell_type":"markdown","source":["Model training procedure:"],"metadata":{"id":"SwaTdulqvdsL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPYtK8x00lLW"},"outputs":[],"source":["def trainmaskrcnn(lossfunction = 'dice'): # took 23 minutes\n","    setloss(lossfunction)\n","    MODELNAME='model5'+lossfunction + '.pt'\n","    LOGSUFFIX = '_LOGS'\n","    savemodel = True\n","    warnings.filterwarnings('ignore')\n","    torch.manual_seed(0)\n","    LEARNING_RATE = 0.003\n","    WEIGHT_DECAY = 0.0005\n","    MOMENTUM = 0.9\n","    NUM_EPOCHS = 7\n","    BATCH_SIZE = 2\n","    filepath = os.path.join(MODELPATH, MODELNAME.split('.')[0] + LOGSUFFIX + '.log')\n","    myfile = Path(filepath)\n","    myfile.touch(exist_ok=True)\n","    logging.basicConfig(\n","        format='%(levelname)s: %(asctime)s %(message)s',\n","        level = logging.DEBUG,\n","        filename = filepath,\n","        filemode='a'\n","    )\n","    logging.info(\"START\")\n","    logging.info(f\"lossfunction: {lossfunction}\")\n","\n","    train = WGISDMaskedDataset('./wgisd', source = 'train')\n","    trainloader = DataLoader(train, BATCH_SIZE, shuffle=True, num_workers = 2, collate_fn=lambda s: tuple(zip(*s)))\n","    valid = WGISDMaskedDataset('./wgisd', source = 'valid')\n","    validloader = DataLoader(valid, BATCH_SIZE, shuffle=True, num_workers = 2, collate_fn=lambda s: tuple(zip(*s)))\n","\n","    model = get_maskrcnn()\n","\n","    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    logging.info(f'DEVICE: {DEVICE}')\n","    model.to(DEVICE)\n","\n","    for param in model.parameters():\n","        param.requires_grad = True\n","    model.train()\n","    params = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.33, verbose = False)\n","    trainlosses = []\n","    trainmasklosses = []\n","    validlosses = []\n","    validmasklosses = []\n","\n","    for epoch in range(1, NUM_EPOCHS + 1):\n","        logging.info(f'Current epoch: {epoch} of {NUM_EPOCHS}')\n","        lossacc= 0.0\n","        lossaccmask = 0.0\n","        model.train()\n","        #TODO add cross validation\n","        for batchid, (images, targets) in enumerate(trainloader, 1):\n","            images = [image.to(DEVICE) for image in images]\n","            targets = [ {k : v.to(DEVICE) for k, v in t.items()}for t in targets]\n","            loss_dict = model(images, targets)\n","            loss = sum(loss_dict.values())\n","            lossmask = loss_dict['loss_mask']\n","\n","            #backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            #logs\n","            lossacc += loss.item()\n","            lossaccmask += lossmask.item()\n","\n","        logging.info(f'Finalepoch{epoch} loss on train: lossacc:{lossacc}')\n","        trainlosses.append(lossacc)\n","        trainmasklosses.append(lossaccmask)\n","\n","        model.train()\n","        logging.info(f'Evaluation...')\n","        validaccloss = 0.0\n","        validacclossmask = 0.0\n","        with torch.no_grad():\n","            for i, (imgs, trgts) in enumerate(validloader, 1):\n","                imgs = [img.to(DEVICE) for img in imgs]\n","                trgts = [ {k : v.to(DEVICE) for k, v in t.items()}for t in trgts]\n","                loss = model(imgs, trgts)\n","                validaccloss += sum(loss.values()).item()\n","                lossmask = loss['loss_mask']\n","                validacclossmask += lossmask.item()\n","        logging.info(f'valid losses: {validaccloss}')\n","        validlosses.append(validaccloss)\n","        validmasklosses.append(validacclossmask)\n","        lr_scheduler.step()\n","    model.eval()\n","    if savemodel == True:\n","        torch.save(model.state_dict(), os.path.join(MODELPATH, MODELNAME))\n","    logging.info('FINISHED')\n","    data=(trainlosses, trainmasklosses), (validlosses, validmasklosses)\n","    with open( MODELPATH + MODELNAME + \"_LOSSES.json\" , \"w\" ) as write:\n","        json.dump( data , write )\n","    return (trainlosses, trainmasklosses), (validlosses, validmasklosses)"]},{"cell_type":"code","source":["print(MODELPATH)\n","availablelosses()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B96Xe37IO69o","outputId":"eda94af0-4bec-42c5-f14e-789e0858af5e","executionInfo":{"status":"ok","timestamp":1643237455705,"user_tz":-60,"elapsed":306,"user":{"displayName":"kposk skpo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05760435175705162862"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/googledrive/MyDrive/\n"]},{"output_type":"execute_result","data":{"text/plain":["['bincrossentr_wl', 'dice', 'iou', 'mse']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["for lossfunction in availablelosses():#took 1h1min37sec\n","    (trainlosses, trainmasklosses), (validlosses, validmasklosses) = trainmaskrcnn(lossfunction = lossfunction)"],"metadata":{"id":"2nr308FIyh85"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2NHfoC6xpdE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7764363-9731-4c41-e2e1-a62401d8d760","executionInfo":{"status":"ok","timestamp":1643237847146,"user_tz":-60,"elapsed":629,"user":{"displayName":"kposk skpo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05760435175705162862"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["runMaskRCNNdifferentlossfoos5.ipynb  Untitled0.ipynb\n"]}],"source":["!ls /googledrive/MyDrive/"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"runMaskRCNNdifferentlossfoos5.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}